\documentclass{article}
\usepackage{graphicx} 
\usepackage{amsmath,amssymb}
\usepackage{parskip}

\title{PAV Proof}
\author{Artem Ivaniuk}
\date{September 29th, 2025}

\begin{document}

\maketitle

\noindent\textbf{Definitions}
\begin{itemize}
  \item $PAV$ = Proportional Approval Voting. Among all subsets $T\subseteq S$ with $|T|=k$, $PAV$ returns a subset that maximizes the $PAV$ score.
  \item $V$ = set of $n$ agents (voters).
  \item $S$ = set of $m$ projects, indexed $1,\dots,m$.
  \item Each voter $i$ casts an approval ballot $A_i\subseteq S$, i.i.d. from other voters.
  \item For each project $j\in S$ there is a ``true'' quality level ($\ell_j$). 
  \item For each project $j\in S$, random voter $i\in V$ let
    \[
      p_j \;=\; \Pr\big(j\in A_i\big)
    \] 
    Assume $p_j=f(\ell_j)$ for some strictly increasing $f$ -- ie, better-quality projects have larger $p_j$.
  \item For a subset $T\subseteq S$ define the per-voter PAV contribution:
    \[
      \phi_T(A_i) \;=\; \sum_{t=1}^{|T\cap A_i|} \frac{1}{t}.
    \]
    (Harmonic-vector weight: a voter who approves \(r\) chosen projects contributes \(1+1/2+\cdots+1/r\) to the PAV score.)
  \item The empirical (total) PAV score of a set \(T\) on the \(n\) ballots is
    \[
      \mathrm{Score}_n(T) \;=\; \sum_{i=1}^n \phi_T(A_i).
    \]
  \item The expected per-voter PAV score of \(T\) is
    \[
      s(T) \;=\; \mathbb{E}\big[\phi_T(A_i)\big],
    \]
    and the population (expected total) score is \(n s(T)\).
  \item Let $\mathcal{T}_k := \{T\subseteq S:|T|=k\}$ denote all size-$k$ subsets. Define the minimal difference between any chosen and any non-chosen projects' PAV scores:
    \[
      D_s \;:=\; \min_{T\in\mathcal{T}_k,\;T'\in\mathcal{T}_k,\;T'\neq T}\big(s(T)-s(T')\big)
    \]
\end{itemize}

\noindent\textbf{Proposition.}  
Assume $D_s>0$. Then
\[
  \Pr\big( PAV(V) \in \arg\max_{T\in\mathcal{T}_k} \mathrm{Score}_n(T) \text{ equals a maximizer of } s(\cdot)\big)
  \;\ge\; 1 - \binom{m}{k}\exp\!\Big(-\frac{2 n D_s^2}{(H_k)^2}\Big),
\]
where \(H_k := 1+\tfrac12+\cdots+\tfrac{1}{k}\). 

\medskip
\noindent\textbf{Proof.}

\textbf{Per-voter contribution.}  
For any set $T$ we have $|T\cap A_i|\le k$, hence the per-voter contribution
\[
  0 \le \phi_T(A_i) \le H_k := \sum_{t=1}^k \frac{1}{t}.
\]
So each random variable $\phi_T(A_i)$ is bounded in the interval $[0,H_k]$.

\textbf{Concentration for a fixed set $T$.}  
For fixed $T\in\mathcal{T}_k$, the $n$ terms $\phi_T(A_1),\dots,\phi_T(A_n)$ are i.i.d.\ with mean $s(T)$ and range at most $H_k$. By Hoeffding's inequality, for any $\varepsilon>0$,
\[
  \Pr\!\big( |\mathrm{Score}_n(T) - n s(T)| \ge n\varepsilon \big)
  = \Pr\!\Big( \Big|\sum_{i=1}^n \big(\phi_T(A_i)-s(T)\big)\Big| \ge n\varepsilon \Big)
  \le 2\exp\!\Big(-\frac{2 n^2 \varepsilon^2}{n (H_k)^2}\Big)
  = 2\exp\!\Big(-\frac{2 n \varepsilon^2}{(H_k)^2}\Big).
\]

\textbf{Concentration over all size-\(k\) sets.}  
There are $\binom{m}{k}$ sets in $\mathcal{T}_k$. Using Union Bound, with probability at least
\[
  1 - 2\binom{m}{k}\exp\!\Big(-\frac{2 n \varepsilon^2}{(H_k)^2}\Big)
\]
for every $T\in\mathcal{T}_k$:
\[
  |\mathrm{Score}_n(T) - n s(T)| < n\varepsilon.
\]

\textbf{Choose $\varepsilon$ as half the population gap.}  
By definition, $D_s>0$ is the minimal positive gap. Then,
\[
  \varepsilon \;=\; \frac{D_s}{2}.
\]
Then for any maximizer $T^\star$ of $s(\cdot)$ and any other set $T\neq T^\star$,
\[
  \mathrm{Score}_n(T^\star) \;\ge\; n s(T^\star) - n\varepsilon
    \;=\; n\big(s(T^\star)-\varepsilon\big)
    \;=\; n\big(s(T)-\varepsilon + (s(T^\star)-s(T))\big)
    \;\ge\; n\big(s(T)+D_s - \varepsilon - \varepsilon\big)
    \;=\; n\big(s(T)\big).
\]
Since $s(T^\star)-s(T)\ge D_s$ and both empirical scores are within $n\varepsilon$ of their means:
\[
  \mathrm{Score}_n(T^\star) - \mathrm{Score}_n(T)
  \ge n\big( (s(T^\star)-\varepsilon) - (s(T)+\varepsilon)\big)
  = n\big( s(T^\star)-s(T) - 2\varepsilon\big)
  \ge 0.
\]
Since $\varepsilon=D_s/2$, the last difference is \(\ge 0\). Thus, under the uniform concentration event, the empirical maximizers coincide with the population maximizers.

\textbf{Probability bound.}  
Using the union bound estimate with $\varepsilon=D_s/2$, we get
\[
  \Pr\big(\text{empirical maximizer equals population maximizer}\big)
  \;\ge\; 1 - 2\binom{m}{k}\exp\!\Big(-\frac{2 n (D_s/2)^2}{(H_k)^2}\Big).
\]
Simplifying:
\[
  \frac{2 n (D_s/2)^2}{(H_k)^2} \;=\; \frac{n D_s^2}{2 (H_k)^2}.
\]

\[
  \Pr\big(PAV(V)\ \text{is a maximizer of } s(\cdot)\big)
  \;\ge\; 1 - \binom{m}{k}\exp\!\Big(-\frac{2 n D_s^2}{(H_k)^2}\Big)
\]
Hence the probability tends to \(1\) exponentially fast in \(n\) whenever \(D_s>0\). \(\square\)

\end{document}
